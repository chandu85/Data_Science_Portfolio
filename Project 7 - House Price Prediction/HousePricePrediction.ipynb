{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python391jvsc74a57bd0aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49",
   "display_name": "Python 3.9.1 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## House Price Prediction\n",
    "\n",
    "The goal for this project is to build the linear regression model, decision tree regression model, and xgboost regression model to predict the house price based on the selected features and see which model performs good."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_profiling as pp\n",
    "\n",
    "# regressors\n",
    "import xgboost\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# pre-processing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# model selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>MSSubClass</th>\n      <th>MSZoning</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>Street</th>\n      <th>Alley</th>\n      <th>LotShape</th>\n      <th>LandContour</th>\n      <th>Utilities</th>\n      <th>...</th>\n      <th>PoolArea</th>\n      <th>PoolQC</th>\n      <th>Fence</th>\n      <th>MiscFeature</th>\n      <th>MiscVal</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n      <th>SaleType</th>\n      <th>SaleCondition</th>\n      <th>SalePrice</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>65.0</td>\n      <td>8450</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>208500</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>80.0</td>\n      <td>9600</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>181500</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>68.0</td>\n      <td>11250</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>9</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>223500</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>70</td>\n      <td>RL</td>\n      <td>60.0</td>\n      <td>9550</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2006</td>\n      <td>WD</td>\n      <td>Abnorml</td>\n      <td>140000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>84.0</td>\n      <td>14260</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>12</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>250000</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 81 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "#Load Data\n",
    "#https://www.kaggle.com/kamelyounes/house-prices-prediction/?select=train.csv\n",
    "df = pd.read_csv(\"Data/train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Summarize dataset:  91%|█████████▏| 86/94 [00:20<00:00, 41.12it/s, Calculate cramers correlation]/usr/local/lib/python3.9/site-packages/pandas_profiling/model/correlations.py:146: UserWarning: There was an attempt to calculate the cramers correlation, but this failed.\n",
      "To hide this warning, disable the calculation\n",
      "(using `df.profile_report(correlations={\"cramers\": {\"calculate\": False}})`\n",
      "If this is problematic for your use case, please report this as an issue:\n",
      "https://github.com/pandas-profiling/pandas-profiling/issues\n",
      "(include the error message: 'No data; `observed` has size 0.')\n",
      "  warnings.warn(\n",
      "Summarize dataset: 100%|██████████| 94/94 [02:44<00:00,  1.75s/it, Completed]\n",
      "Generate report structure: 100%|██████████| 1/1 [00:27<00:00, 27.50s/it]\n",
      "Render HTML: 100%|██████████| 1/1 [00:28<00:00, 28.60s/it]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00,  6.41it/s]\n"
     ]
    }
   ],
   "source": [
    "# Pandas Profiling\n",
    "# Print the Pandas dataframe profile\n",
    "profile = pp.ProfileReport(df)\n",
    "profile.to_file(\"df_profile.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Id                 0\nMSSubClass         0\nMSZoning           0\nLotFrontage      259\nLotArea            0\n                ... \nMoSold             0\nYrSold             0\nSaleType           0\nSaleCondition      0\nSalePrice          0\nLength: 81, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check to see if we have any missing data rows\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Id               0\n",
       "MSSubClass       0\n",
       "MSZoning         0\n",
       "LotFrontage      0\n",
       "LotArea          0\n",
       "                ..\n",
       "MoSold           0\n",
       "YrSold           0\n",
       "SaleType         0\n",
       "SaleCondition    0\n",
       "SalePrice        0\n",
       "Length: 81, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# Handle the missing data\n",
    "for key, values in df.iteritems():\n",
    "    if (pd.api.types.is_numeric_dtype(df[key])):\n",
    "        df[key].fillna(value= df[key].mean(), inplace=True)\n",
    "    else :\n",
    "        df[key].fillna(value= \"Missing\", inplace=True) \n",
    "\n",
    "    \n",
    "pd.Series(df.isnull().sum())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use label encoder to handle the non-numeric data and split data for test and training.abs\n",
    "one_hot_enc = LabelEncoder()\n",
    "for key, values in df.iteritems():\n",
    "    if (pd.api.types.is_string_dtype(df[key])):        \n",
    "           df[key] = one_hot_enc.fit_transform(df[key])\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df)\n",
    "scaler.transform(df)\n",
    "\n",
    "X = df.drop('SalePrice', 1)\n",
    "y = df.SalePrice\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "source": [
    "### Build Regression Models\n",
    "\n",
    "Build different types of regression models and compare them."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### 1. Linear Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "linear regression score : 0.7372746490015494\n"
     ]
    }
   ],
   "source": [
    "# linear regression grid search\n",
    "grid_search_linear_reg = GridSearchCV(LinearRegression(), { 'fit_intercept': [True, False],\n",
    "                                                        'normalize': [True, False], \n",
    "                                                        'copy_X': [True, False] \n",
    "                                                        }, cv=5)\n",
    "grid_search_linear_reg.fit(X_train, y_train)\n",
    "print(\"linear regression score :\", grid_search_linear_reg.best_score_)"
   ]
  },
  {
   "source": [
    "#### 2. Decision tree grid search"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "decision trees score : 0.7426745240489036\n"
     ]
    }
   ],
   "source": [
    "# decision tree grid search\n",
    "decision_tree_param_grid = {'criterion': ['mse', 'mae'],\n",
    "              'min_samples_split': [10, 20, 40],\n",
    "              'max_depth': [2, 6, 8],\n",
    "              'min_samples_leaf': [20, 40, 100],\n",
    "              'max_leaf_nodes': [5, 20, 100],\n",
    "              }\n",
    "\n",
    "grid_search_decision_trees = GridSearchCV(DecisionTreeRegressor(), decision_tree_param_grid, cv=5)\n",
    "grid_search_decision_trees.fit(X_train, y_train)\n",
    "print(\"decision trees score :\", grid_search_decision_trees.best_score_)"
   ]
  },
  {
   "source": [
    "#### 3. XGBoost grid search"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=None, gamma=None,\n",
       "                                          gpu_id=None, importance_type='gain',\n",
       "                                          interaction_constraints=None,\n",
       "                                          learning_rate=None,\n",
       "                                          max_delta_step=None, max_depth=None,\n",
       "                                          min_child_weight=None, missing=nan,\n",
       "                                          monotone_constraints=None,\n",
       "                                          n_estimators=100, n...\n",
       "                                          validate_parameters=None,\n",
       "                                          verbosity=None),\n",
       "                   n_iter=50, n_jobs=4,\n",
       "                   param_distributions={'base_score': [0.25, 0.5, 0.75, 1],\n",
       "                                        'booster': ['gbtree', 'gblinear'],\n",
       "                                        'learning_rate': [0.05, 0.1, 0.15, 0.2],\n",
       "                                        'max_depth': [2, 3, 5, 10, 15],\n",
       "                                        'min_child_weight': [1, 2, 3, 4],\n",
       "                                        'n_estimators': [100, 500, 900, 1100,\n",
       "                                                         1500]},\n",
       "                   random_state=42, return_train_score=True,\n",
       "                   scoring='neg_mean_absolute_error', verbose=5)"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "# xgboost grid search\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 500, 900, 1100, 1500],\n",
    "    'max_depth': [2,3,5,10,15],\n",
    "    'learning_rate': [0.05, 0.1, 0.15, 0.2],\n",
    "    'min_child_weight': [1,2,3,4],\n",
    "    'booster': ['gbtree','gblinear'],\n",
    "    'base_score': [0.25, 0.5, 0.75, 1]\n",
    "}\n",
    "grid_search_xgb = RandomizedSearchCV(xgboost.XGBRegressor(), param_distributions = xgb_param_grid,\n",
    "                              cv=5, n_iter=50,\n",
    "                              scoring = 'neg_mean_absolute_error', n_jobs = 4,\n",
    "                              verbose = 5,\n",
    "                              return_train_score = True,\n",
    "                              random_state = 42)\n",
    "grid_search_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "xgb score : 0.8812320408719397\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the xgboost regression model\n",
    "xgb_best_estimator = grid_search_xgb.best_estimator_\n",
    "print(\"xgb score :\",cross_val_score(xgb_best_estimator, X_train, y_train, cv=5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8822907013437441"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "xgb_best_estimator.fit(X_train, y_train)\n",
    "xgb_best_estimator.score(X_test, y_test)"
   ]
  },
  {
   "source": [
    "### Conclusion  \n",
    "- Out of the three models we have tried, xgboost model seem to have performed better which higher score. The score on training set and testing set are very close indicating that there is no overfitting of the training data in the model.\n",
    "\n",
    "### References\n",
    "- https://www.kaggle.com/kamelyounes/house-prices-prediction#data\n",
    "- https://www.kaggle.com/kamelyounes/house-prices-prediction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}